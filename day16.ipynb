{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m frameCount \u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     flag, img \u001b[39m=\u001b[39m vid\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m flag:\n\u001b[0;32m     14\u001b[0m         faces \u001b[39m=\u001b[39m fd\u001b[39m.\u001b[39mdetectMultiScale(\n\u001b[0;32m     15\u001b[0m             cv2\u001b[39m.\u001b[39mcvtColor(img,cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY),\n\u001b[0;32m     16\u001b[0m             scaleFactor \u001b[39m=\u001b[39m \u001b[39m1.1\u001b[39m,\n\u001b[0;32m     17\u001b[0m             minNeighbors \u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     18\u001b[0m             minSize \u001b[39m=\u001b[39m (\u001b[39m50\u001b[39m,\u001b[39m50\u001b[39m)\n\u001b[0;32m     19\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import face_recognition as fr\n",
    "enc =[]\n",
    "names =[]\n",
    "vid = cv2.VideoCapture()\n",
    "fd = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "frameCount =0\n",
    "while True:\n",
    "    flag, img = vid.read()\n",
    "    if flag:\n",
    "        faces = fd.detectMultiScale(\n",
    "            cv2.cvtColor(img,cv2.COLOR_BGR2GRAY),\n",
    "            scaleFactor = 1.1,\n",
    "            minNeighbors =5,\n",
    "            minSize = (50,50)\n",
    "        )\n",
    "        if len(faces)==1:\n",
    "            x,y,w,h = faces[0]\n",
    "            img_face = img[y:y+h,x:x+w,:].copy()\n",
    "            img_face = cv2.resize(img_face,(400,400), \n",
    "                                  interpolation=cv2.INTER_CUBIC)\n",
    "            #cv2.imwrite(f'{name}_{frameCount}.png',img_face)\n",
    "            face_encoding = fr.face_encodings(img_face)\n",
    "            print(face_encoding)\n",
    "            if(len(face_encoding[0])):\n",
    "                enc.append(face_encoding[0])\n",
    "                names.append(name)\n",
    "                frameCount  +=1\n",
    "                if frameCount ==frameLimit:\n",
    "                    data = {'name':names, 'encoding':enc}\n",
    "                    pd.DataFrame(data).to_csv('faces_data.csv')\n",
    "                    break\n",
    "\n",
    "\n",
    "        cv2.imshow('preview',img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import face_recognition as fr\n",
    "enc =[]\n",
    "names =[]\n",
    "vid = cv2.VideoCapture()\n",
    "fd = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    ")\n",
    "try:\n",
    "    face_db =pd.read_csv('faces_data.csv', index_col =0)\n",
    "    data = {\n",
    "        'name':face_db['name'].values.tolist(),\n",
    "        'encoding':face_db['encoding'].value.tolist(),\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    face_db = {'name':[], 'encoding':[]}\n",
    "    \n",
    "\n",
    "frameCount =0\n",
    "frameLimit =20\n",
    "name=input('Enter your name:')\n",
    "while True:\n",
    "    flag, img = vid.read()\n",
    "    if flag:\n",
    "        faces = fd.detectMultiScale(\n",
    "            cv2.cvtColor(img,cv2.COLOR_BGR2GRAY),\n",
    "            scaleFactor = 1.1,\n",
    "            minNeighbors =5,\n",
    "            minSize = (50,50)\n",
    "        )\n",
    "        if len(faces)==1:\n",
    "            x,y,w,h = faces[0]\n",
    "            img_face = img[y:y+h,x:x+w,:].copy()\n",
    "            img_face = cv2.resize(img_face,(400,400), \n",
    "                                  interpolation=cv2.INTER_CUBIC)\n",
    "            #cv2.imwrite(f'{name}_{frameCount}.png',img_face)\n",
    "            face_encoding = fr.face_encodings(img_face)\n",
    "            print(face_encoding)\n",
    "            if(len(face_encoding[0])):\n",
    "                enc.append(face_encoding[0])\n",
    "                names.append(name)\n",
    "                frameCount  +=1\n",
    "                if frameCount ==frameLimit:\n",
    "                    data = {'name':names, 'encoding':enc}\n",
    "                    pd.DataFrame(data).to_csv('faces_data.csv')\n",
    "                    break\n",
    "\n",
    "\n",
    "        cv2.imshow('preview',img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
